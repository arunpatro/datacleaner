{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_md5(file_path):\n",
    "    \"\"\"Calculate the MD5 hash of a file.\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def list_files_and_hashes(directory):\n",
    "    \"\"\"List all files in the directory and calculate their MD5 hash.\"\"\"\n",
    "    files_data = []\n",
    "    total_files = sum([len(files) for _, _, files in os.walk(directory)])\n",
    "    print(f\"Total files to process: {total_files}\")\n",
    "\n",
    "    for root, dirs, files in tqdm(os.walk(directory), desc=\"Scanning directories\"):\n",
    "        for file in tqdm(files, desc=f\"Processing files in {root}\", leave=False):\n",
    "            file_path = os.path.join(root, file)\n",
    "            if os.path.islink(file_path):\n",
    "                continue\n",
    "            file_hash = calculate_md5(file_path)\n",
    "            files_data.append({\n",
    "                'path': file_path,\n",
    "                'hash': file_hash,\n",
    "                'size': os.path.getsize(file_path),\n",
    "                'last_modified': os.path.getmtime(file_path)\n",
    "            })\n",
    "    return files_data\n",
    "\n",
    "def save_data_to_json(data, filename):\n",
    "    \"\"\"Save the file data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"File data saved to {filename}\")\n",
    "\n",
    "def load_data_from_json(filename):\n",
    "    \"\"\"Load file data from a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def detect_duplicates(files_data):\n",
    "    \"\"\"Detect duplicate files based on their MD5 hash.\"\"\"\n",
    "    hash_dict = {}\n",
    "    duplicates = []\n",
    "    for file in tqdm(files_data, desc=\"Detecting duplicates\"):\n",
    "        file_hash = file['hash']\n",
    "        if file_hash in hash_dict:\n",
    "            duplicates.append((hash_dict[file_hash], file))\n",
    "        else:\n",
    "            hash_dict[file_hash] = file\n",
    "    return duplicates\n",
    "\n",
    "def main():\n",
    "    directory = \"/Users/arunpatro/My Drive\"  # Input directory\n",
    "    output_file = \"file_data.json\"\n",
    "\n",
    "    print(f\"Scanning directory: {directory}\")\n",
    "    \n",
    "    # List files and calculate their MD5 hash\n",
    "    files_data = list_files_and_hashes(directory)\n",
    "\n",
    "    # Save data to JSON\n",
    "    save_data_to_json(files_data, output_file)\n",
    "\n",
    "    # Load data from JSON\n",
    "    loaded_data = load_data_from_json(output_file)\n",
    "\n",
    "    # Detect duplicates\n",
    "    print(\"Detecting duplicate files...\")\n",
    "    duplicates = detect_duplicates(loaded_data)\n",
    "    \n",
    "    if duplicates:\n",
    "        print(\"Duplicate files found:\")\n",
    "        for dup in duplicates:\n",
    "            print(f\"Original: {dup[0]['path']} <--> Duplicate: {dup[1]['path']}\")\n",
    "    else:\n",
    "        print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: /Users/arunpatro/My Drive\n",
      "Total files to process: 19322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning directories: 695it [01:02, 11.19it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/arunpatro/My Drive/IIT - KGP/AGV/AGV Treat/IMG_2615.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScanning directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# List files and calculate their MD5 hash\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m files_data \u001b[38;5;241m=\u001b[39m \u001b[43mlist_files_and_hashes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Save data to JSON\u001b[39;00m\n\u001b[1;32m     65\u001b[0m save_data_to_json(files_data, output_file)\n",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m, in \u001b[0;36mlist_files_and_hashes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m tqdm(files, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing files in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     22\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file)\n\u001b[0;32m---> 23\u001b[0m         file_hash \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_md5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m         files_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: file_path,\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m'\u001b[39m: file_hash,\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(file_path),\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_modified\u001b[39m\u001b[38;5;124m'\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetmtime(file_path)\n\u001b[1;32m     29\u001b[0m         })\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m files_data\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mcalculate_md5\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the MD5 hash of a file.\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m hash_md5 \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39mmd5()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: f\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4096\u001b[39m), \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     11\u001b[0m         hash_md5\u001b[38;5;241m.\u001b[39mupdate(chunk)\n",
      "File \u001b[0;32m~/miniforge3/envs/arun/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/arunpatro/My Drive/IIT - KGP/AGV/AGV Treat/IMG_2615.JPG'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
